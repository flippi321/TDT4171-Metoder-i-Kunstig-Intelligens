{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqvI8S20lEfB",
        "outputId": "c9970ae6-b31e-499b-afe0-43b71dc82b10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No GPU found. Running on CPU.\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "from typing import Dict, List, Any, Union\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.utils import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Flatten, Dense, LSTM, BatchNormalization, Dropout, LeakyReLU\n",
        "\n",
        "# Ensure TensorFlow uses GPU if available\n",
        "gpu_devices = tf.config.list_physical_devices('GPU')\n",
        "if gpu_devices:\n",
        "    for device in gpu_devices:\n",
        "        tf.config.experimental.set_memory_growth(device, True)\n",
        "    print(\"GPU is available and will be used.\")\n",
        "else:\n",
        "    print(\"No GPU found. Running on CPU.\")\n",
        "\n",
        "def load_data() -> Dict[str, Union[List[Any], int]]:\n",
        "    path = \"keras-data.pickle\"\n",
        "    with open(file=path, mode=\"rb\") as file:\n",
        "        data = pickle.load(file)\n",
        "    return data\n",
        "\n",
        "def preprocess_data(data: Dict[str, Union[List[Any], int]]) -> Dict[str, Union[List[Any], np.ndarray, int]]:\n",
        "    \"\"\"\n",
        "    Preprocesses the data dictionary. Both the training-data and the test-data must be padded\n",
        "    to the same length; play around with the maxlen parameter to trade off speed and accuracy.\n",
        "    \"\"\"\n",
        "    maxlen = data[\"max_length\"]//16\n",
        "    data[\"x_train\"] = pad_sequences(data['x_train'], maxlen=maxlen)\n",
        "    data[\"y_train\"] = np.asarray(data['y_train'])\n",
        "    data[\"x_test\"] = pad_sequences(data['x_test'], maxlen=maxlen)\n",
        "    data[\"y_test\"] = np.asarray(data['y_test'])\n",
        "\n",
        "    return data\n",
        "\n",
        "def train_model(data: Dict[str, Union[List[Any], np.ndarray, int]], model_type=\"feedforward\", lr=1e-3, epochs = 1) -> float:\n",
        "    \"\"\"\n",
        "    Build a neural network of type model_type and train the model on the data.\n",
        "    Evaluate the accuracy of the model on test data.\n",
        "\n",
        "    :param data: The dataset dictionary to train neural network on\n",
        "    :param model_type: The model to be trained, either \"feedforward\" for feedforward network\n",
        "                        or \"recurrent\" for recurrent network\n",
        "    :return: The accuracy of the model on test data\n",
        "    \"\"\"\n",
        "    vocab_size = data[\"vocab_size\"]\n",
        "    embedding_dim = 128\n",
        "    maxlen = data[\"x_train\"].shape[1]\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen))\n",
        "\n",
        "    if model_type == \"feedforward\":\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(256, kernel_initializer=\"he_normal\"))\n",
        "        model.add(LeakyReLU(negative_slope=0.1))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.3))\n",
        "\n",
        "        model.add(Dense(128, kernel_initializer=\"he_normal\"))\n",
        "        model.add(LeakyReLU(negative_slope=0.1))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.3))\n",
        "\n",
        "        model.add(Dense(64, activation=tf.keras.activations.swish, kernel_initializer=\"he_normal\"))\n",
        "        model.add(Dense(32, activation='relu'))\n",
        "        model.add(Dense(16, activation='relu'))\n",
        "    elif model_type == \"recurrent\":\n",
        "        model.add(LSTM(128, return_sequences=False))\n",
        "        model.add(Dense(64, activation='relu'))\n",
        "    else:\n",
        "        raise ValueError(\"Invalid model_type. Choose 'feedforward' or 'recurrent'.\")\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    optim = keras.optimizers.Adam(learning_rate=lr)\n",
        "    model.compile(optimizer=optim, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(data[\"x_train\"], data[\"y_train\"], epochs=epochs, validation_split=0.2, verbose=1)\n",
        "\n",
        "    loss, accuracy = model.evaluate(data[\"x_test\"], data[\"y_test\"], verbose=0)\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp_w6eKB3J3b",
        "outputId": "3aa6fe41-8dee-432f-94fc-b16b0b637fd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Loading data...\n",
            "2. Preprocessing data...\n"
          ]
        }
      ],
      "source": [
        "print(\"1. Loading data...\")\n",
        "keras_data = load_data()\n",
        "print(\"2. Preprocessing data...\")\n",
        "keras_data = preprocess_data(keras_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5s-phyx3JxS",
        "outputId": "2809d0b9-e604-425e-890b-fc9023b48e08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3. Training feedforward neural network...\n",
            "Epoch 1/3\n",
            "\u001b[1m9827/9827\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 45ms/step - accuracy: 0.8448 - loss: 0.3455 - val_accuracy: 0.8881 - val_loss: 0.2604\n",
            "Epoch 2/3\n",
            "\u001b[1m9827/9827\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 38ms/step - accuracy: 0.8893 - loss: 0.2611 - val_accuracy: 0.8958 - val_loss: 0.2464\n",
            "Epoch 3/3\n",
            "\u001b[1m9827/9827\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 36ms/step - accuracy: 0.9052 - loss: 0.2274 - val_accuracy: 0.8963 - val_loss: 0.2482\n",
            "Model: Feedforward NN.\n",
            "Test accuracy: 0.895\n"
          ]
        }
      ],
      "source": [
        "print(\"3. Training feedforward neural network...\")\n",
        "fnn_test_accuracy = train_model(keras_data, model_type=\"feedforward\", epochs=3)\n",
        "print('Model: Feedforward NN.\\n'\n",
        "      f'Test accuracy: {fnn_test_accuracy:.3f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45bmc7oM3JpA",
        "outputId": "0dd0ebca-234a-4ec3-80ff-e73dcac89bdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4. Training recurrent neural network...\n",
            "\u001b[1m9827/9827\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 36ms/step - accuracy: 0.8819 - loss: 0.2753 - val_accuracy: 0.9231 - val_loss: 0.1875\n",
            "Model: Recurrent NN.\n",
            "Test accuracy: 0.922\n"
          ]
        }
      ],
      "source": [
        "print(\"4. Training recurrent neural network...\")\n",
        "rnn_test_accuracy = train_model(keras_data, model_type=\"recurrent\")\n",
        "print('Model: Recurrent NN.\\n'\n",
        "      f'Test accuracy: {rnn_test_accuracy:.3f}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
